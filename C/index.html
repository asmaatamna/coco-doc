<!-- HTML header for doxygen 1.8.8-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
    <head>
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <!-- For Mobile Devices -->
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
        <meta name="generator" content="Doxygen 1.8.11"/>
        <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
        <title>coco-doc-C: The COCO/NumBBO experiments interface</title>
        <!--<link href="tabs.css" rel="stylesheet" type="text/css"/>-->
        <script type="text/javascript" src="dynsections.js"></script>
        <link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
        <link href="doxygen.css" rel="stylesheet" type="text/css" />
        <link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<link href="bootstrap.css" rel="stylesheet" type="text/css"/>
        <link rel="stylesheet" href="bootstrap.css">
        <script type="text/javascript" src="bootstrap.js"></script>
        <script type="text/javascript" src="customdoxygen.js"></script>
    </head>
    <body>
        <nav class="navbar navbar-default" role="navigation">
            <div class="container">
                <div class="navbar-header">
                    <a class="navbar-brand">coco-doc-C </a>
                </div>
            </div>
        </nav>
        <div id="top"><!-- do not remove this div, it is closed by doxygen! -->
            <div class="content" id="content">
                <div class="container">
                    <div class="row">
                        <div class="col-sm-12 panel panel-default" style="padding-bottom: 15px;">
                            <div style="margin-bottom: 15px;">
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="annotated.html"><span>Data&#160;Structures</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">The COCO/NumBBO experiments interface </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a href="https://github.com/numbbo/coco">COCO (COmparing Continuous Optimisers)</a> is a platform for systematic and sound comparisons of real-parameter global optimisers mainly developed within the <a href="http://numbbo.gforge.inria.fr/doku.php">NumBBO project</a>. COCO provides benchmark function testbeds, experimentation templates which are easy to parallelize, and tools for processing and visualizing data generated by one or several optimizers.</p>
<p>For a getting started guide see <a href="https://github.com/numbbo/coco/blob/master/README.md#getting-started">here</a>.</p>
<p><b>Reimplementation of COCO in ANSI C</b></p>
<p>In order to allow for easier maintenance and further extensions of the COCO platform, it was rewritten entirely from 2014 till 2016. Now, a single implementation in ANSI C (aka C89) is used and called from the other languages to conduct the experiments. This documentation of the COCO C code serves therefore as the basic reference for:</p><ul>
<li><a href="#benchmarking">How to conduct benchmarking experiments in C</a></li>
<li><a href="#new-suites">How to write new test functions and combine them into test suites</a></li>
<li><a href="#new-indicators">How to write additional performance indicators and logging functionality</a></li>
</ul>
<p><b>Pointers to the source code and other documentation</b></p>
<p>The actual source code of COCO can be found at <a href="http://github.com/numbbo/coco">http://github.com/numbbo/coco</a></p>
<p>More information about the biobjective test suite (bbob-biobj) can be found at <a href="http://numbbo.github.io/coco-doc/bbob-biobj/functions/">http://numbbo.github.io/coco-doc/bbob-biobj/functions/</a></p>
<p>How to conduct experiments in all supported languages is described at <a href="http://numbbo.github.io/bbob-biobj-experiments-doc">http://numbbo.github.io/bbob-biobj-experiments-doc</a> (coming soon)</p>
<h2>How to conduct benchmarking experiments in C <a class="anchor" id="benchmarking"></a></h2>
<p>At this point we assume that the <code>example_experiment</code> in C is running on your machine (see the <a href="https://github.com/numbbo/coco/blob/master/README.md#getting-started">getting started guide</a> if you need any assistance). The best way to create your own benchmark experiment is to copy that example and make the changes you need to include your optimizer.</p>
<p>In order to simplify the interface between the optimizers and the COCO platform, a static pointer to a COCO problem and a function type for evaluation functions are used: </p><pre class="fragment">static coco_problem_t *PROBLEM;
typedef void (*evaluate_function_t)(const double *x, double *y);
</pre><p>Benchmarking a single run of the algorithm <code>my_optimizer</code> on the <code>bbob-biobj</code> suite with default parameters is invoked in the following way (see below for explanation of the <a href="#suite-parameters">suite parameters</a> and <a href="#observer-parameters">observer parameters</a>): </p><pre class="fragment">coco_suite_t *suite;
coco_observer_t *observer;

suite = coco_suite("bbob-biobj", "", "");
observer = coco_observer("bbob-biobj", "");

while ((PROBLEM = coco_suite_get_next_problem(suite, observer)) != NULL) {
  size_t dimension = coco_problem_get_dimension(PROBLEM);

  my_optimizer(evaluate_function, 
               dimension,
               coco_problem_get_number_of_objectives(PROBLEM),
               coco_problem_get_smallest_values_of_interest(PROBLEM),
               coco_problem_get_largest_values_of_interest(PROBLEM),
               dimension * BUDGET_MULTIPLIER,
               random_generator);
}  

coco_observer_free(observer);
coco_suite_free(suite);
</pre><p>The <code>coco_suite_t</code> object is a collection of (in this case biobjective) optimization problems of type <code>coco_problem_t</code>. The while loop iterates through all problems of the suite and optimizes each of them with <code>my_optimizer</code> (a simple random search is used in the <code>example_experiment</code>). The <code>coco_observer_t</code> object takes care of logging the performance of the optimizer. The interface to <code>my_optimizer</code> includes the following parameters:</p><ul>
<li>the function that evaluates solutions on the optimization problem in question,</li>
<li>the number of variables (dimension),</li>
<li>the number of objectives,</li>
<li>the smallest and largest values of interest, which define the region of interest in the decision space,</li>
<li>the maximal budget of evaluations and</li>
<li>the random generator.</li>
</ul>
<p>The optimizer should be run until <code>dimension * BUDGET_MULTIPLIER</code> number of evaluations have been reached. In the <code>example_experiment</code>, the <code>BUDGET_MULTIPLIER</code> is conservatively set using </p><pre class="fragment">static const size_t BUDGET_MULTIPLIER = 2;
</pre><p>so that the experiment runs quickly. You need to increase the budget for your real benchmarking experiments, but do so gradually (you might want to test <code>BUDGET_MULTIPLIER = 1e2</code> before you use any larger values) to see how it effects the running time of the benchmark.</p>
<p>The actual <code>example_experiment</code> contains an additional loop that supports <b>independent restarts</b> by <code>my_optimizer</code> and takes care of breaking the loop when the target has been hit or the budget of function evaluations has been exhausted. While the simple random search used in the example does not trigger restarts by itself, your optimizer most probably should (in order to avoid being stuck in a local optimum). When restarting the algorithm make sure that the optimizer is not doing the exaclty same thing in every run.</p>
<p>The <code>example_experiment</code> records the time needed for optimizing a problem and can therefore serve also as a <b>timing experiment</b> for your algorithm.</p>
<p>Note that the benchmarking procedure remains the same whether we are dealing with single- or multi-objective problems and algorithms. To perform benchmarking on a different suite and with a different observer, just replace <code>"bbob-biobj"</code> with the name of the desired suite and observer.</p>
<p>In the above example, the suite and observer are called without additional parameters (the empty strings <code>""</code> are used), which means that their default values apply. These can be changed by calling: </p><pre class="fragment">suite = coco_suite("bbob-biobj", suite_instance, suite_options);
observer = coco_observer("bbob-biobj", observer_options);
</pre><p>where <code>suite_instance</code>, <code>suite_options</code> and <code>observer_options</code> are strings with parameters encoded as pairs <code>"key: value"</code>. When the value consists of one or more integers, it can be encoded using the syntax <code>m-n</code> (meaning all integer values from m to n), <code>-n</code> (meaning all values up to n), <code>n-</code> (meaning all values from n on) and even <code>-</code> (meaning all available values); or by simply listing the values separated by commas (as in <code>2,3,5</code>). No spaces are allowed in the definition of a range or list of values.</p>
<h3>Suite parameters <a class="anchor" id="suite-parameters"></a></h3>
<p>The suite contains a collection of problems constructed by a Cartesian product of the suite's optimization functions, dimensions and instances. The functions and dimensions are defined by the suite name, while the instances are defined with the <code>suite_instance</code> parameter. The suite can be filtered by specifying functions, dimensions and instances through the <code>suite_options</code> parameter.</p>
<p>Possible keys and values for <code>suite_instance</code> are:</p><ul>
<li>either <code>"year: YEAR"</code>, where <code>YEAR</code> is usually the year of the corresponding <a href="http://numbbo.github.io/workshops">BBOB workshop</a> defining the instances used in that year's benchmark,</li>
<li>or <code>"instances: VALUES"</code>, where <code>VALUES</code> is a list or a range <code>m-n</code> of instances you wish to include in the suite (starting from 1).</li>
</ul>
<p>If both <code>year</code> and <code>instances</code> appear in the <code>suite_instance</code> string, only the first one is taken into account. If no <code>suite_instance</code> is given, it defaults to the year of the current BBOB workshop.</p>
<p>Possible keys and values for <code>suite_options</code> are:</p><ul>
<li><code>dimensions: LIST</code>, where <code>LIST</code> is the list of dimensions to keep in the suite (range-style syntax is not allowed here),</li>
<li><code>dimension_indices: VALUES</code>, where <code>VALUES</code> is a list or a range of dimension indices (starting from 1) to keep in the suite, and</li>
<li><code>function_indices: VALUES</code>, where <code>VALUES</code> is a list or a range of function indices (starting from 1) to keep in the suite, and</li>
<li><code>instance_indices: VALUES</code>, where <code>VALUES</code> is a list or a range of instance indices (starting from 1) to keep in the suite.</li>
</ul>
<p>If both <code>dimensions</code> and <code>dimension_indices</code> appear in the <code>suite_options</code> string, only the first one is taken into account. If no <code>suite_options</code> is given, no filtering by functions, dimensions and instances is performed, i.e. the experiment will be run on the entire benchmark suite.</p>
<p>For example, the call: </p><pre class="fragment">suite = coco_suite("bbob-biobj", 
                   "instances: 10-20", 
                   "dimensions: 2,3,5,10,20 instance_indices:1-5");
</pre><p>first creates the biobjective suite with instances 10 to 20, but then uses only the first five dimensions (skipping dimension 40) and the first five instances (i.e. instances 10 to 14) of the suite.</p>
<p>This kind of filtering can be helpful when parallelizing the benchmark.</p>
<p>See <a href="http://numbbo.github.io/coco-doc/bbob-biobj/functions/">biobjective test suite</a> and <a href="http://coco.lri.fr/downloads/download15.03/bbobdocfunctions.pdf">bbob test sute</a> for more detailed information on the two currently supported suites.</p>
<h3>Observer parameters <a class="anchor" id="observer-parameters"></a></h3>
<p>The observer controls the logging that is performed within the benchmark. Some observer parameters are general, while others are specific to the chosen observer.</p>
<p>Possible keys and values for the general <code>observer_options</code> are:</p><ul>
<li><code>result_folder: NAME</code>, determines the folder within the "exdata" folder into which the results will be output. If the folder with the given name already exists, first NAME_001 will be tried, then NAME_002 and so on. The default value is "default".</li>
<li><code>algorithm_name: NAME</code>, where <code>NAME</code> is a short name of the algorithm that will be used in plots (no spaces are allowed). The default value is "ALG".</li>
<li><code>algorithm_info: STRING</code> stores the description of the algorithm. If it contains spaces, it must be surrounded by double quotes. The default value is "" (no description).</li>
<li><code>number_target_triggers: VALUE</code> defines the number of targets between each 10**i and 10**(i+1) (equally spaced in the logarithmic scale) that trigger logging. The default value is 100.</li>
<li><code>target_precision: VALUE</code> defines the precision used for targets (there are no targets for abs(values) &lt; target_precision). The default value is 1e-8.</li>
<li><code>number_evaluation_triggers: VALUE</code> defines the number of evaluations to be logged between each 10**i and 10**(i+1). The default value is 20.</li>
<li><code>base_evaluation_triggers: VALUES</code> defines the base evaluations used to produce an additional evaluation-based logging. The numbers of evaluations that trigger logging are every base_evaluation * dimension * (10**i). For example, if base_evaluation_triggers = "1,2,5", the logger will be triggered by evaluations dim*1, dim*2, dim*5, 10*dim*1, 10*dim*2, 10*dim*5, 100*dim*1, 100*dim*2, 100*dim*5, ... The default value is "1,2,5".</li>
<li><code>precision_x: VALUE</code> defines the precision used when outputting variables and corresponds to the number of digits to be printed after the decimal point. The default value is 8.</li>
<li><code>precision_f: VALUE</code> defines the precision used when outputting f values and corresponds to the number of digits to be printed after the decimal point. The default value is 15.</li>
</ul>
<p>Possible keys and values for the <code>observer_options</code> of the <code>bbob-biobj</code> observer are:</p><ul>
<li><code>log_nondominated: STRING</code> determines which nondominated solutions to log. <code>STRING</code> can take on the values <code>none</code> (don't log nondominated solutions), <code>final</code> (log only the final nondominated solutions) and <code>all</code> (log every solution that is nondominated at creation time). The default value is all.</li>
<li><code>log_decision_variables: STRING</code> determines whether the decision variables are to be logged in addition to the objective variables in the output of nondominated solutions. <code>STRING</code> can take on the values <code>none</code> (don't output decision variables), <code>low_dim</code>(output decision variables only for dimensions lower or equal to 5) and <code>all</code> (output all decision variables). The default value is log_dim.</li>
<li><code>compute_indicators : VALUE</code> determines whether to compute and output performance indicators (<code>1</code>) or not (<code>0</code>). The default value is 1.</li>
<li><code>produce_all_data: VALUE</code> determines whether to produce all data required for the workshop. If set to <code>1</code>, it overwrites some other options and is equivalent to setting <code>log_nondominated</code> to <code>all</code>, <code>log_decision_variables</code> to <code>low_dim</code> and <code>compute_indicators</code> to <code>1</code>. If set to <code>0</code>, it does not change the values of the other options. The default value is 0.</li>
</ul>
<p>You can also run the benchmark without any observer, which produces no output, by invoking either <code>""</code> or <code>"no_observer"</code> in place of the observer name.</p>
<h3>Problem evaluation <a class="anchor" id="problem-evaluation"></a></h3>
<p>In order to evaluate the problem, call the function: </p><pre class="fragment">void coco_evaluate_function(coco_problem_t *problem, const double *x, double *y);
</pre><p>It will evaluate the problem function in point <code>x</code> and save the result in <code>y</code>.</p>
<p>In order to evaluate the constraints of the problem, call the function: </p><pre class="fragment">void coco_evaluate_function(coco_problem_t *problem, const double *x, double *y);
</pre><p>It will evaluate the problem constraints in point <code>x</code> and save the result in <code>y</code>. Note: while this functionality is provided, the framework does not yet include problems with constraints.</p>
<h3>Problem properties <a class="anchor" id="problem-properties"></a></h3>
<p>To learn more about the problem, you can access its properties in the following way: </p><pre class="fragment">/* Returns the number of variables i.e. dimension of the problem */
size_t coco_problem_get_dimension(const coco_problem_t *problem);

/* Returns a vector of size 'dimension' with lower bounds of the region of interest in 
 * the decision space. */
const double *coco_problem_get_smallest_values_of_interest(const coco_problem_t *problem);

/* Returns a vector of size 'dimension' with upper bounds of the region of interest in 
 * the decision space. */
const double *coco_problem_get_largest_values_of_interest(const coco_problem_t *problem);

/* Returns the number of objectives of the problem */
size_t coco_problem_get_number_of_objectives(const coco_problem_t *problem);

/* Returns the number of evaluations done on the problem */
size_t coco_problem_get_evaluations(coco_problem_t *problem);
</pre><p>See the <code><a class="el" href="coco_8h.html" title="All public COCO functions, constants and variables are defined in this file. ">coco.h</a></code> file for more information on these and other functions you can use to interface COCO problem and other COCO structures.</p>
<h2>How to write new test functions and combine them into test suites <a class="anchor" id="new-suites"></a></h2>
<p>COMING SOON...</p>
<h2>How to write additional performance indicators and logging functionality <a class="anchor" id="new-indicators"></a></h2>
<p>COMING SOON... </p>
</div></div><!-- contents -->
<!-- HTML footer for doxygen 1.8.8-->
<!-- start footer part -->
</div>
</div>
</div>
</div>
</div>
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
</body>
</html>
